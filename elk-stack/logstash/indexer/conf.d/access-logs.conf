input {
    redis {
        host => "127.0.0.1"
        port => "16384"
        threads => 5
        data_type => "list"
        key => "logstash"
        #type => "redis-input"
        type => "nginx-access"
    }
}

filter {
    grok {
        match => ["message",  "^%{DATA:remote_addr}\t%{DATA:http_x_forwarded_for}\t%{DATA:remote_user}\t%{DATA:time_local}\t%{DATA:scheme}\t%{DATA:request_method}\t%{DATA:request}\t%{DATA:args}\t%{DATA:server_protocol}\t%{NUMBER:status:int}\t%{DATA:http_referer}\t%{DATA:http_user_agent}\t%{NUMBER:request_length:int}\t%{NUMBER:bytes_sent:int}\t%{DATA:upstream_addr}\t%{DATA:upstream_response_time:float}\t%{NUMBER:request_time:float}\t%{DATA:cookie___URM_UID__}$"]
        }
    grok {
        match => ["path","^.*/%{DATA:domain_name}.access.log$" ]
    }
    date {
        # 以日志中的时间字段作为该条日志发生的时间
        match => ["time_local","dd/MMM/yyyy:HH:mm:ss Z"]
    }
    mutate {
        # 去掉不需要的字段
        remove_field => [ "time_local" ]
    }
    ruby {
        # 增加一个字段标记该条日志进 elk 的时间
        code => "event.set('intoelk_date', Time.new)"
    }
}

output {
    elasticsearch {
        hosts => "127.0.0.1"
        index => "logstash-accesslog-%{+YYYY.MM.dd}"
        template_overwrite => true
    }
}
